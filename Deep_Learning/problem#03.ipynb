{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB5KkWA6_RuP",
        "outputId": "2a8e88f5-6841-4e0f-9934-646a39c0ad17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Trainable Parameters: 5258\n",
            "Epoch [1/20], Train Loss: 0.3432, Train Accuracy: 90.19%, Val Loss: 0.1118, Val Accuracy: 96.93%\n",
            "Epoch [2/20], Train Loss: 0.1049, Train Accuracy: 96.86%, Val Loss: 0.0774, Val Accuracy: 97.68%\n",
            "Epoch [3/20], Train Loss: 0.0805, Train Accuracy: 97.54%, Val Loss: 0.0641, Val Accuracy: 98.04%\n",
            "Epoch [4/20], Train Loss: 0.0676, Train Accuracy: 97.89%, Val Loss: 0.0596, Val Accuracy: 98.20%\n",
            "Epoch [5/20], Train Loss: 0.0603, Train Accuracy: 98.14%, Val Loss: 0.0517, Val Accuracy: 98.44%\n",
            "Epoch [6/20], Train Loss: 0.0555, Train Accuracy: 98.27%, Val Loss: 0.0456, Val Accuracy: 98.63%\n",
            "Epoch [7/20], Train Loss: 0.0512, Train Accuracy: 98.39%, Val Loss: 0.0485, Val Accuracy: 98.39%\n",
            "Epoch [8/20], Train Loss: 0.0473, Train Accuracy: 98.52%, Val Loss: 0.0485, Val Accuracy: 98.53%\n",
            "Epoch [9/20], Train Loss: 0.0453, Train Accuracy: 98.59%, Val Loss: 0.0466, Val Accuracy: 98.50%\n",
            "Epoch [10/20], Train Loss: 0.0417, Train Accuracy: 98.71%, Val Loss: 0.0446, Val Accuracy: 98.66%\n",
            "Epoch [11/20], Train Loss: 0.0398, Train Accuracy: 98.77%, Val Loss: 0.0439, Val Accuracy: 98.67%\n",
            "Epoch [12/20], Train Loss: 0.0373, Train Accuracy: 98.81%, Val Loss: 0.0419, Val Accuracy: 98.73%\n",
            "Epoch [13/20], Train Loss: 0.0360, Train Accuracy: 98.90%, Val Loss: 0.0433, Val Accuracy: 98.70%\n",
            "Epoch [14/20], Train Loss: 0.0343, Train Accuracy: 98.89%, Val Loss: 0.0443, Val Accuracy: 98.68%\n",
            "Epoch [15/20], Train Loss: 0.0335, Train Accuracy: 98.94%, Val Loss: 0.0414, Val Accuracy: 98.75%\n",
            "Epoch [16/20], Train Loss: 0.0307, Train Accuracy: 99.03%, Val Loss: 0.0413, Val Accuracy: 98.64%\n",
            "Epoch [17/20], Train Loss: 0.0302, Train Accuracy: 99.07%, Val Loss: 0.0431, Val Accuracy: 98.54%\n",
            "Epoch [18/20], Train Loss: 0.0292, Train Accuracy: 99.06%, Val Loss: 0.0465, Val Accuracy: 98.65%\n",
            "Epoch [19/20], Train Loss: 0.0274, Train Accuracy: 99.11%, Val Loss: 0.0473, Val Accuracy: 98.61%\n",
            "Epoch [20/20], Train Loss: 0.0271, Train Accuracy: 99.16%, Val Loss: 0.0438, Val Accuracy: 98.74%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "train_dataset = MNIST(root='data/', train=True, transform=ToTensor(), download=True)\n",
        "test_dataset = MNIST(root='data/', train=False, transform=ToTensor())\n",
        "\n",
        "# Define the model\n",
        "class PureCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PureCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3)\n",
        "        self.fc = nn.Linear(16 * 5 * 5, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = PureCNN()\n",
        "\n",
        "# Count the total number of trainable parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Total Trainable Parameters:\", total_params)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move the model to the device\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_accuracy = 100.0 * train_correct / len(train_loader.dataset)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "    val_loss /= len(test_loader.dataset)\n",
        "    val_accuracy = 100.0 * val_correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
        "    \n",
        "    # # Check if validation accuracy threshold is reached\n",
        "    # if val_accuracy >= 99.40:\n",
        "    #     break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Conv2D(8, kernel_size=3, activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Conv2D(16, kernel_size=3, activation='relu'),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Count the total number of trainable parameters\n",
        "total_params = model.count_params()\n",
        "print(\"Total Trainable Parameters:\", total_params)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train, batch_size=64, epochs=1, verbose=2)\n",
        "\n",
        "    # Evaluate the model\n",
        "    _, train_accuracy = model.evaluate(x_train, y_train, verbose=0)\n",
        "    _, val_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "          f\"Train Accuracy: {train_accuracy:.4f}%, \"\n",
        "          f\"Val Accuracy: {val_accuracy:.4f}%\")\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJlh2-KZA9VJ",
        "outputId": "e790bd46-e740-4abe-9b21-3bd5089dc652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Trainable Parameters: 5258\n",
            "938/938 - 4s - loss: 0.3544 - accuracy: 0.8979 - 4s/epoch - 4ms/step\n",
            "Epoch [1/20], Train Accuracy: 0.9598%, Val Accuracy: 0.9622%\n",
            "938/938 - 3s - loss: 0.1108 - accuracy: 0.9664 - 3s/epoch - 3ms/step\n",
            "Epoch [2/20], Train Accuracy: 0.9730%, Val Accuracy: 0.9751%\n",
            "938/938 - 3s - loss: 0.0829 - accuracy: 0.9749 - 3s/epoch - 3ms/step\n",
            "Epoch [3/20], Train Accuracy: 0.9781%, Val Accuracy: 0.9783%\n",
            "938/938 - 3s - loss: 0.0694 - accuracy: 0.9787 - 3s/epoch - 3ms/step\n",
            "Epoch [4/20], Train Accuracy: 0.9810%, Val Accuracy: 0.9814%\n",
            "938/938 - 3s - loss: 0.0610 - accuracy: 0.9816 - 3s/epoch - 3ms/step\n",
            "Epoch [5/20], Train Accuracy: 0.9825%, Val Accuracy: 0.9816%\n",
            "938/938 - 3s - loss: 0.0548 - accuracy: 0.9837 - 3s/epoch - 3ms/step\n",
            "Epoch [6/20], Train Accuracy: 0.9836%, Val Accuracy: 0.9826%\n",
            "938/938 - 3s - loss: 0.0499 - accuracy: 0.9848 - 3s/epoch - 3ms/step\n",
            "Epoch [7/20], Train Accuracy: 0.9849%, Val Accuracy: 0.9834%\n",
            "938/938 - 3s - loss: 0.0459 - accuracy: 0.9862 - 3s/epoch - 3ms/step\n",
            "Epoch [8/20], Train Accuracy: 0.9857%, Val Accuracy: 0.9839%\n",
            "938/938 - 3s - loss: 0.0426 - accuracy: 0.9871 - 3s/epoch - 3ms/step\n",
            "Epoch [9/20], Train Accuracy: 0.9861%, Val Accuracy: 0.9837%\n",
            "938/938 - 3s - loss: 0.0397 - accuracy: 0.9880 - 3s/epoch - 3ms/step\n",
            "Epoch [10/20], Train Accuracy: 0.9868%, Val Accuracy: 0.9842%\n",
            "938/938 - 3s - loss: 0.0371 - accuracy: 0.9887 - 3s/epoch - 3ms/step\n",
            "Epoch [11/20], Train Accuracy: 0.9875%, Val Accuracy: 0.9844%\n",
            "938/938 - 3s - loss: 0.0347 - accuracy: 0.9895 - 3s/epoch - 3ms/step\n",
            "Epoch [12/20], Train Accuracy: 0.9882%, Val Accuracy: 0.9842%\n",
            "938/938 - 3s - loss: 0.0327 - accuracy: 0.9900 - 3s/epoch - 3ms/step\n",
            "Epoch [13/20], Train Accuracy: 0.9890%, Val Accuracy: 0.9844%\n",
            "938/938 - 3s - loss: 0.0308 - accuracy: 0.9906 - 3s/epoch - 3ms/step\n",
            "Epoch [14/20], Train Accuracy: 0.9891%, Val Accuracy: 0.9843%\n",
            "938/938 - 3s - loss: 0.0291 - accuracy: 0.9913 - 3s/epoch - 3ms/step\n",
            "Epoch [15/20], Train Accuracy: 0.9898%, Val Accuracy: 0.9844%\n",
            "938/938 - 3s - loss: 0.0275 - accuracy: 0.9920 - 3s/epoch - 3ms/step\n",
            "Epoch [16/20], Train Accuracy: 0.9905%, Val Accuracy: 0.9850%\n",
            "938/938 - 3s - loss: 0.0260 - accuracy: 0.9925 - 3s/epoch - 3ms/step\n",
            "Epoch [17/20], Train Accuracy: 0.9908%, Val Accuracy: 0.9856%\n",
            "938/938 - 3s - loss: 0.0246 - accuracy: 0.9930 - 3s/epoch - 3ms/step\n",
            "Epoch [18/20], Train Accuracy: 0.9912%, Val Accuracy: 0.9858%\n",
            "938/938 - 3s - loss: 0.0233 - accuracy: 0.9933 - 3s/epoch - 3ms/step\n",
            "Epoch [19/20], Train Accuracy: 0.9918%, Val Accuracy: 0.9862%\n",
            "938/938 - 3s - loss: 0.0220 - accuracy: 0.9937 - 3s/epoch - 3ms/step\n",
            "Epoch [20/20], Train Accuracy: 0.9922%, Val Accuracy: 0.9867%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "train_dataset = MNIST(root='data/', train=True, transform=ToTensor(), download=True)\n",
        "test_dataset = MNIST(root='data/', train=False, transform=ToTensor())\n",
        "\n",
        "# Define the model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
        "        self.fc = nn.Linear(16 * 7 * 7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 16 * 7 * 7)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleCNN()\n",
        "\n",
        "# Count the total number of trainable parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Total Trainable Parameters:\", total_params)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move the model to the device\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_accuracy = 100.0 * train_correct / len(train_loader.dataset)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "    val_loss /= len(test_loader.dataset)\n",
        "    val_accuracy = 100.0 * val_correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}%, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_RIup3RDFs2",
        "outputId": "c7b7343f-0b2f-450c-af0f-506f55b74c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Trainable Parameters: 9098\n",
            "Epoch [1/20], Train Loss: 0.3215, Train Accuracy: 90.7600%, Val Loss: 0.1041, Val Accuracy: 96.7900%\n",
            "Epoch [2/20], Train Loss: 0.1005, Train Accuracy: 97.0533%, Val Loss: 0.0678, Val Accuracy: 97.7500%\n",
            "Epoch [3/20], Train Loss: 0.0764, Train Accuracy: 97.6617%, Val Loss: 0.0604, Val Accuracy: 98.0600%\n",
            "Epoch [4/20], Train Loss: 0.0628, Train Accuracy: 98.0983%, Val Loss: 0.0533, Val Accuracy: 98.3900%\n",
            "Epoch [5/20], Train Loss: 0.0545, Train Accuracy: 98.3450%, Val Loss: 0.0498, Val Accuracy: 98.4100%\n",
            "Epoch [6/20], Train Loss: 0.0470, Train Accuracy: 98.6067%, Val Loss: 0.0451, Val Accuracy: 98.5900%\n",
            "Epoch [7/20], Train Loss: 0.0427, Train Accuracy: 98.6650%, Val Loss: 0.0376, Val Accuracy: 98.8100%\n",
            "Epoch [8/20], Train Loss: 0.0385, Train Accuracy: 98.8450%, Val Loss: 0.0422, Val Accuracy: 98.6400%\n",
            "Epoch [9/20], Train Loss: 0.0358, Train Accuracy: 98.9017%, Val Loss: 0.0412, Val Accuracy: 98.7200%\n",
            "Epoch [10/20], Train Loss: 0.0327, Train Accuracy: 99.0017%, Val Loss: 0.0383, Val Accuracy: 98.8200%\n",
            "Epoch [11/20], Train Loss: 0.0296, Train Accuracy: 99.0950%, Val Loss: 0.0376, Val Accuracy: 98.7800%\n",
            "Epoch [12/20], Train Loss: 0.0275, Train Accuracy: 99.1283%, Val Loss: 0.0420, Val Accuracy: 98.6500%\n",
            "Epoch [13/20], Train Loss: 0.0260, Train Accuracy: 99.1717%, Val Loss: 0.0369, Val Accuracy: 98.7600%\n",
            "Epoch [14/20], Train Loss: 0.0244, Train Accuracy: 99.1967%, Val Loss: 0.0365, Val Accuracy: 98.7900%\n",
            "Epoch [15/20], Train Loss: 0.0234, Train Accuracy: 99.2150%, Val Loss: 0.0402, Val Accuracy: 98.7500%\n",
            "Epoch [16/20], Train Loss: 0.0210, Train Accuracy: 99.3183%, Val Loss: 0.0353, Val Accuracy: 98.8200%\n",
            "Epoch [17/20], Train Loss: 0.0205, Train Accuracy: 99.3350%, Val Loss: 0.0367, Val Accuracy: 98.8100%\n",
            "Epoch [18/20], Train Loss: 0.0185, Train Accuracy: 99.4233%, Val Loss: 0.0420, Val Accuracy: 98.7800%\n",
            "Epoch [19/20], Train Loss: 0.0177, Train Accuracy: 99.4383%, Val Loss: 0.0360, Val Accuracy: 98.9100%\n",
            "Epoch [20/20], Train Loss: 0.0174, Train Accuracy: 99.4267%, Val Loss: 0.0369, Val Accuracy: 98.8000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "train_dataset = MNIST(root='data/', train=True, transform=ToTensor(), download=True)\n",
        "test_dataset = MNIST(root='data/', train=False, transform=ToTensor())\n",
        "\n",
        "# Define the model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
        "        self.fc = nn.Linear(16 * 7 * 7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 16 * 7 * 7)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleCNN()\n",
        "\n",
        "# Count the total number of trainable parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Total Trainable Parameters:\", total_params)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move the model to the device\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_accuracy = 100.0 * train_correct / len(train_loader.dataset)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "    val_loss /= len(test_loader.dataset)\n",
        "    val_accuracy = 100.0 * val_correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "_Koi_BFbGxLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "train_dataset = MNIST(root='data/', train=True, transform=ToTensor(), download=True)\n",
        "test_dataset = MNIST(root='data/', train=False, transform=ToTensor())\n",
        "\n",
        "# Define the model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.fc = nn.Linear(32 * 7 * 7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = nn.functional.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 32 * 7 * 7)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleCNN()\n",
        "\n",
        "# Count the total number of trainable parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Total Trainable Parameters:\", total_params)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move the model to the device\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_accuracy = 100.0 * train_correct / len(train_loader.dataset)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "    val_loss /= len(test_loader.dataset)\n",
        "    val_accuracy = 100.0 * val_correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}%, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}%\")\n"
      ],
      "metadata": {
        "id": "C9XA-uQKMBPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "train_dataset = MNIST(root='data/', train=True, transform=ToTensor(), download=True)\n",
        "test_dataset = MNIST(root='data/', train=False, transform=ToTensor())\n",
        "\n",
        "# Define the model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 4, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(4)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(8)\n",
        "        self.fc = nn.Linear(8 * 7 * 7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = nn.functional.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 8 * 7 * 7)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleCNN()\n",
        "\n",
        "# Count the total number of trainable parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Total Trainable Parameters:\", total_params)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move the model to the device\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_accuracy = 100.0 * train_correct / len(train_loader.dataset)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "    val_loss /= len(test_loader.dataset)\n",
        "    val_accuracy = 100.0 * val_correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}%, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNqa7jM9Mx8D",
        "outputId": "1fa32966-0107-4cdd-9706-0abdd33ccb4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Trainable Parameters: 4290\n",
            "Epoch [1/50], Train Loss: 0.2273, Train Accuracy: 93.7017%, Val Loss: 0.0927, Val Accuracy: 97.1800%\n",
            "Epoch [2/50], Train Loss: 0.0790, Train Accuracy: 97.5933%, Val Loss: 0.0714, Val Accuracy: 97.6500%\n",
            "Epoch [3/50], Train Loss: 0.0658, Train Accuracy: 97.9617%, Val Loss: 0.0539, Val Accuracy: 98.3000%\n",
            "Epoch [4/50], Train Loss: 0.0586, Train Accuracy: 98.1867%, Val Loss: 0.0521, Val Accuracy: 98.3900%\n",
            "Epoch [5/50], Train Loss: 0.0530, Train Accuracy: 98.3950%, Val Loss: 0.0584, Val Accuracy: 98.2800%\n",
            "Epoch [6/50], Train Loss: 0.0496, Train Accuracy: 98.4733%, Val Loss: 0.0535, Val Accuracy: 98.3200%\n",
            "Epoch [7/50], Train Loss: 0.0470, Train Accuracy: 98.5367%, Val Loss: 0.0481, Val Accuracy: 98.4500%\n",
            "Epoch [8/50], Train Loss: 0.0442, Train Accuracy: 98.6000%, Val Loss: 0.0482, Val Accuracy: 98.4300%\n",
            "Epoch [9/50], Train Loss: 0.0430, Train Accuracy: 98.6167%, Val Loss: 0.0465, Val Accuracy: 98.5600%\n",
            "Epoch [10/50], Train Loss: 0.0400, Train Accuracy: 98.7083%, Val Loss: 0.0515, Val Accuracy: 98.4200%\n",
            "Epoch [11/50], Train Loss: 0.0389, Train Accuracy: 98.7833%, Val Loss: 0.0586, Val Accuracy: 98.0600%\n",
            "Epoch [12/50], Train Loss: 0.0386, Train Accuracy: 98.7850%, Val Loss: 0.0522, Val Accuracy: 98.3500%\n",
            "Epoch [13/50], Train Loss: 0.0369, Train Accuracy: 98.8233%, Val Loss: 0.0488, Val Accuracy: 98.3900%\n",
            "Epoch [14/50], Train Loss: 0.0354, Train Accuracy: 98.8367%, Val Loss: 0.0535, Val Accuracy: 98.3700%\n",
            "Epoch [15/50], Train Loss: 0.0344, Train Accuracy: 98.8733%, Val Loss: 0.0450, Val Accuracy: 98.5700%\n",
            "Epoch [16/50], Train Loss: 0.0338, Train Accuracy: 98.9050%, Val Loss: 0.0497, Val Accuracy: 98.4200%\n",
            "Epoch [17/50], Train Loss: 0.0320, Train Accuracy: 98.9900%, Val Loss: 0.0501, Val Accuracy: 98.5100%\n",
            "Epoch [18/50], Train Loss: 0.0311, Train Accuracy: 98.9783%, Val Loss: 0.0543, Val Accuracy: 98.2800%\n",
            "Epoch [19/50], Train Loss: 0.0305, Train Accuracy: 99.0017%, Val Loss: 0.0514, Val Accuracy: 98.4700%\n",
            "Epoch [20/50], Train Loss: 0.0296, Train Accuracy: 99.0417%, Val Loss: 0.0533, Val Accuracy: 98.4200%\n",
            "Epoch [21/50], Train Loss: 0.0292, Train Accuracy: 99.0217%, Val Loss: 0.0506, Val Accuracy: 98.5300%\n",
            "Epoch [22/50], Train Loss: 0.0293, Train Accuracy: 99.1000%, Val Loss: 0.0525, Val Accuracy: 98.4400%\n",
            "Epoch [23/50], Train Loss: 0.0284, Train Accuracy: 99.0217%, Val Loss: 0.0465, Val Accuracy: 98.6000%\n",
            "Epoch [24/50], Train Loss: 0.0269, Train Accuracy: 99.1183%, Val Loss: 0.0550, Val Accuracy: 98.4000%\n",
            "Epoch [25/50], Train Loss: 0.0270, Train Accuracy: 99.1050%, Val Loss: 0.0485, Val Accuracy: 98.6700%\n",
            "Epoch [26/50], Train Loss: 0.0254, Train Accuracy: 99.1867%, Val Loss: 0.0529, Val Accuracy: 98.5300%\n",
            "Epoch [27/50], Train Loss: 0.0261, Train Accuracy: 99.1217%, Val Loss: 0.0549, Val Accuracy: 98.4400%\n",
            "Epoch [28/50], Train Loss: 0.0257, Train Accuracy: 99.1233%, Val Loss: 0.0570, Val Accuracy: 98.4600%\n",
            "Epoch [29/50], Train Loss: 0.0239, Train Accuracy: 99.2400%, Val Loss: 0.0607, Val Accuracy: 98.4400%\n",
            "Epoch [30/50], Train Loss: 0.0243, Train Accuracy: 99.1917%, Val Loss: 0.0532, Val Accuracy: 98.5800%\n",
            "Epoch [31/50], Train Loss: 0.0245, Train Accuracy: 99.2050%, Val Loss: 0.0561, Val Accuracy: 98.5600%\n",
            "Epoch [32/50], Train Loss: 0.0232, Train Accuracy: 99.2767%, Val Loss: 0.0679, Val Accuracy: 98.2500%\n",
            "Epoch [33/50], Train Loss: 0.0229, Train Accuracy: 99.2933%, Val Loss: 0.0528, Val Accuracy: 98.4900%\n",
            "Epoch [34/50], Train Loss: 0.0223, Train Accuracy: 99.2600%, Val Loss: 0.0587, Val Accuracy: 98.3600%\n",
            "Epoch [35/50], Train Loss: 0.0214, Train Accuracy: 99.3183%, Val Loss: 0.0671, Val Accuracy: 98.2800%\n",
            "Epoch [36/50], Train Loss: 0.0223, Train Accuracy: 99.2733%, Val Loss: 0.0612, Val Accuracy: 98.4200%\n",
            "Epoch [37/50], Train Loss: 0.0215, Train Accuracy: 99.3033%, Val Loss: 0.0597, Val Accuracy: 98.4200%\n",
            "Epoch [38/50], Train Loss: 0.0216, Train Accuracy: 99.2850%, Val Loss: 0.0593, Val Accuracy: 98.3400%\n",
            "Epoch [39/50], Train Loss: 0.0211, Train Accuracy: 99.2733%, Val Loss: 0.0564, Val Accuracy: 98.6000%\n",
            "Epoch [40/50], Train Loss: 0.0210, Train Accuracy: 99.3150%, Val Loss: 0.0550, Val Accuracy: 98.5800%\n",
            "Epoch [41/50], Train Loss: 0.0195, Train Accuracy: 99.3600%, Val Loss: 0.0637, Val Accuracy: 98.3600%\n",
            "Epoch [42/50], Train Loss: 0.0198, Train Accuracy: 99.3400%, Val Loss: 0.0690, Val Accuracy: 98.2900%\n",
            "Epoch [43/50], Train Loss: 0.0191, Train Accuracy: 99.3533%, Val Loss: 0.0633, Val Accuracy: 98.3400%\n",
            "Epoch [44/50], Train Loss: 0.0197, Train Accuracy: 99.3167%, Val Loss: 0.0649, Val Accuracy: 98.4600%\n",
            "Epoch [45/50], Train Loss: 0.0186, Train Accuracy: 99.3650%, Val Loss: 0.0674, Val Accuracy: 98.3500%\n",
            "Epoch [46/50], Train Loss: 0.0192, Train Accuracy: 99.3750%, Val Loss: 0.0652, Val Accuracy: 98.3000%\n",
            "Epoch [47/50], Train Loss: 0.0191, Train Accuracy: 99.3767%, Val Loss: 0.0664, Val Accuracy: 98.4400%\n",
            "Epoch [48/50], Train Loss: 0.0187, Train Accuracy: 99.3967%, Val Loss: 0.0625, Val Accuracy: 98.4400%\n",
            "Epoch [49/50], Train Loss: 0.0176, Train Accuracy: 99.4033%, Val Loss: 0.0664, Val Accuracy: 98.3000%\n",
            "Epoch [50/50], Train Loss: 0.0189, Train Accuracy: 99.3933%, Val Loss: 0.0628, Val Accuracy: 98.5100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Conv2D(4, kernel_size=3, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Conv2D(8, kernel_size=3, padding='same', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Count the total number of trainable parameters\n",
        "total_params = model.count_params()\n",
        "print(\"Total Trainable Parameters:\", total_params)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train, batch_size=32, epochs=1, verbose=2)\n",
        "\n",
        "    # Evaluate the model\n",
        "    _, train_accuracy = model.evaluate(x_train, y_train, verbose=0)\n",
        "    _, val_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "          f\"Train Accuracy: {train_accuracy:.4f}%, \"\n",
        "          f\"Val Accuracy: {val_accuracy:.4f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxv4Uw1eRHNb",
        "outputId": "5b41a617-9aea-44a0-ce44-1900aa9921ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Trainable Parameters: 4314\n",
            "1875/1875 - 8s - loss: 0.2231 - accuracy: 0.9305 - 8s/epoch - 4ms/step\n",
            "Epoch [1/50], Train Accuracy: 0.9695%, Val Accuracy: 0.9668%\n",
            "1875/1875 - 6s - loss: 0.0834 - accuracy: 0.9738 - 6s/epoch - 3ms/step\n",
            "Epoch [2/50], Train Accuracy: 0.9745%, Val Accuracy: 0.9697%\n",
            "1875/1875 - 6s - loss: 0.0677 - accuracy: 0.9790 - 6s/epoch - 3ms/step\n",
            "Epoch [3/50], Train Accuracy: 0.9773%, Val Accuracy: 0.9726%\n",
            "1875/1875 - 6s - loss: 0.0588 - accuracy: 0.9819 - 6s/epoch - 3ms/step\n",
            "Epoch [4/50], Train Accuracy: 0.9808%, Val Accuracy: 0.9766%\n",
            "1875/1875 - 5s - loss: 0.0532 - accuracy: 0.9837 - 5s/epoch - 3ms/step\n",
            "Epoch [5/50], Train Accuracy: 0.9822%, Val Accuracy: 0.9772%\n",
            "1875/1875 - 6s - loss: 0.0492 - accuracy: 0.9850 - 6s/epoch - 3ms/step\n",
            "Epoch [6/50], Train Accuracy: 0.9824%, Val Accuracy: 0.9771%\n",
            "1875/1875 - 6s - loss: 0.0459 - accuracy: 0.9861 - 6s/epoch - 3ms/step\n",
            "Epoch [7/50], Train Accuracy: 0.9847%, Val Accuracy: 0.9779%\n",
            "1875/1875 - 6s - loss: 0.0430 - accuracy: 0.9869 - 6s/epoch - 3ms/step\n",
            "Epoch [8/50], Train Accuracy: 0.9859%, Val Accuracy: 0.9786%\n",
            "1875/1875 - 5s - loss: 0.0404 - accuracy: 0.9873 - 5s/epoch - 3ms/step\n",
            "Epoch [9/50], Train Accuracy: 0.9863%, Val Accuracy: 0.9784%\n",
            "1875/1875 - 5s - loss: 0.0382 - accuracy: 0.9883 - 5s/epoch - 3ms/step\n",
            "Epoch [10/50], Train Accuracy: 0.9865%, Val Accuracy: 0.9784%\n",
            "1875/1875 - 6s - loss: 0.0364 - accuracy: 0.9890 - 6s/epoch - 3ms/step\n",
            "Epoch [11/50], Train Accuracy: 0.9867%, Val Accuracy: 0.9781%\n",
            "1875/1875 - 5s - loss: 0.0347 - accuracy: 0.9896 - 5s/epoch - 3ms/step\n",
            "Epoch [12/50], Train Accuracy: 0.9869%, Val Accuracy: 0.9786%\n",
            "1875/1875 - 6s - loss: 0.0333 - accuracy: 0.9901 - 6s/epoch - 3ms/step\n",
            "Epoch [13/50], Train Accuracy: 0.9870%, Val Accuracy: 0.9794%\n",
            "1875/1875 - 6s - loss: 0.0321 - accuracy: 0.9907 - 6s/epoch - 3ms/step\n",
            "Epoch [14/50], Train Accuracy: 0.9865%, Val Accuracy: 0.9792%\n",
            "1875/1875 - 5s - loss: 0.0310 - accuracy: 0.9909 - 5s/epoch - 3ms/step\n",
            "Epoch [15/50], Train Accuracy: 0.9870%, Val Accuracy: 0.9796%\n",
            "1875/1875 - 5s - loss: 0.0300 - accuracy: 0.9912 - 5s/epoch - 3ms/step\n",
            "Epoch [16/50], Train Accuracy: 0.9872%, Val Accuracy: 0.9805%\n",
            "1875/1875 - 6s - loss: 0.0289 - accuracy: 0.9918 - 6s/epoch - 3ms/step\n",
            "Epoch [17/50], Train Accuracy: 0.9876%, Val Accuracy: 0.9800%\n",
            "1875/1875 - 6s - loss: 0.0280 - accuracy: 0.9919 - 6s/epoch - 3ms/step\n",
            "Epoch [18/50], Train Accuracy: 0.9883%, Val Accuracy: 0.9800%\n",
            "1875/1875 - 6s - loss: 0.0270 - accuracy: 0.9924 - 6s/epoch - 3ms/step\n",
            "Epoch [19/50], Train Accuracy: 0.9886%, Val Accuracy: 0.9807%\n",
            "1875/1875 - 5s - loss: 0.0262 - accuracy: 0.9926 - 5s/epoch - 3ms/step\n",
            "Epoch [20/50], Train Accuracy: 0.9884%, Val Accuracy: 0.9805%\n",
            "1875/1875 - 5s - loss: 0.0257 - accuracy: 0.9927 - 5s/epoch - 3ms/step\n",
            "Epoch [21/50], Train Accuracy: 0.9887%, Val Accuracy: 0.9804%\n",
            "1875/1875 - 6s - loss: 0.0248 - accuracy: 0.9930 - 6s/epoch - 3ms/step\n",
            "Epoch [22/50], Train Accuracy: 0.9892%, Val Accuracy: 0.9804%\n",
            "1875/1875 - 6s - loss: 0.0243 - accuracy: 0.9933 - 6s/epoch - 3ms/step\n",
            "Epoch [23/50], Train Accuracy: 0.9895%, Val Accuracy: 0.9807%\n",
            "1875/1875 - 5s - loss: 0.0238 - accuracy: 0.9933 - 5s/epoch - 3ms/step\n",
            "Epoch [24/50], Train Accuracy: 0.9894%, Val Accuracy: 0.9801%\n",
            "1875/1875 - 6s - loss: 0.0232 - accuracy: 0.9937 - 6s/epoch - 3ms/step\n",
            "Epoch [25/50], Train Accuracy: 0.9897%, Val Accuracy: 0.9804%\n",
            "1875/1875 - 5s - loss: 0.0228 - accuracy: 0.9936 - 5s/epoch - 3ms/step\n",
            "Epoch [26/50], Train Accuracy: 0.9893%, Val Accuracy: 0.9804%\n",
            "1875/1875 - 6s - loss: 0.0223 - accuracy: 0.9937 - 6s/epoch - 3ms/step\n",
            "Epoch [27/50], Train Accuracy: 0.9881%, Val Accuracy: 0.9798%\n",
            "1875/1875 - 5s - loss: 0.0220 - accuracy: 0.9939 - 5s/epoch - 3ms/step\n",
            "Epoch [28/50], Train Accuracy: 0.9886%, Val Accuracy: 0.9799%\n",
            "1875/1875 - 6s - loss: 0.0214 - accuracy: 0.9940 - 6s/epoch - 3ms/step\n",
            "Epoch [29/50], Train Accuracy: 0.9885%, Val Accuracy: 0.9798%\n",
            "1875/1875 - 6s - loss: 0.0207 - accuracy: 0.9944 - 6s/epoch - 3ms/step\n",
            "Epoch [30/50], Train Accuracy: 0.9879%, Val Accuracy: 0.9796%\n",
            "1875/1875 - 6s - loss: 0.0204 - accuracy: 0.9942 - 6s/epoch - 3ms/step\n",
            "Epoch [31/50], Train Accuracy: 0.9874%, Val Accuracy: 0.9788%\n",
            "1875/1875 - 5s - loss: 0.0203 - accuracy: 0.9943 - 5s/epoch - 3ms/step\n",
            "Epoch [32/50], Train Accuracy: 0.9871%, Val Accuracy: 0.9777%\n",
            "1875/1875 - 6s - loss: 0.0197 - accuracy: 0.9945 - 6s/epoch - 3ms/step\n",
            "Epoch [33/50], Train Accuracy: 0.9881%, Val Accuracy: 0.9782%\n",
            "1875/1875 - 6s - loss: 0.0193 - accuracy: 0.9948 - 6s/epoch - 3ms/step\n",
            "Epoch [34/50], Train Accuracy: 0.9882%, Val Accuracy: 0.9785%\n",
            "1875/1875 - 5s - loss: 0.0187 - accuracy: 0.9948 - 5s/epoch - 3ms/step\n",
            "Epoch [35/50], Train Accuracy: 0.9873%, Val Accuracy: 0.9777%\n",
            "1875/1875 - 5s - loss: 0.0188 - accuracy: 0.9948 - 5s/epoch - 3ms/step\n",
            "Epoch [36/50], Train Accuracy: 0.9878%, Val Accuracy: 0.9786%\n",
            "1875/1875 - 5s - loss: 0.0182 - accuracy: 0.9948 - 5s/epoch - 3ms/step\n",
            "Epoch [37/50], Train Accuracy: 0.9875%, Val Accuracy: 0.9780%\n",
            "1875/1875 - 5s - loss: 0.0181 - accuracy: 0.9948 - 5s/epoch - 3ms/step\n",
            "Epoch [38/50], Train Accuracy: 0.9890%, Val Accuracy: 0.9779%\n",
            "1875/1875 - 6s - loss: 0.0176 - accuracy: 0.9949 - 6s/epoch - 3ms/step\n",
            "Epoch [39/50], Train Accuracy: 0.9879%, Val Accuracy: 0.9775%\n",
            "1875/1875 - 6s - loss: 0.0174 - accuracy: 0.9951 - 6s/epoch - 3ms/step\n",
            "Epoch [40/50], Train Accuracy: 0.9877%, Val Accuracy: 0.9785%\n",
            "1875/1875 - 5s - loss: 0.0174 - accuracy: 0.9949 - 5s/epoch - 3ms/step\n",
            "Epoch [41/50], Train Accuracy: 0.9898%, Val Accuracy: 0.9787%\n",
            "1875/1875 - 5s - loss: 0.0166 - accuracy: 0.9951 - 5s/epoch - 3ms/step\n",
            "Epoch [42/50], Train Accuracy: 0.9893%, Val Accuracy: 0.9787%\n",
            "1875/1875 - 6s - loss: 0.0161 - accuracy: 0.9954 - 6s/epoch - 3ms/step\n",
            "Epoch [43/50], Train Accuracy: 0.9896%, Val Accuracy: 0.9782%\n",
            "1875/1875 - 5s - loss: 0.0160 - accuracy: 0.9954 - 5s/epoch - 3ms/step\n",
            "Epoch [44/50], Train Accuracy: 0.9890%, Val Accuracy: 0.9770%\n",
            "1875/1875 - 5s - loss: 0.0156 - accuracy: 0.9955 - 5s/epoch - 3ms/step\n",
            "Epoch [45/50], Train Accuracy: 0.9902%, Val Accuracy: 0.9783%\n",
            "1875/1875 - 5s - loss: 0.0163 - accuracy: 0.9949 - 5s/epoch - 3ms/step\n",
            "Epoch [46/50], Train Accuracy: 0.9902%, Val Accuracy: 0.9790%\n",
            "1875/1875 - 6s - loss: 0.0150 - accuracy: 0.9958 - 6s/epoch - 3ms/step\n",
            "Epoch [47/50], Train Accuracy: 0.9894%, Val Accuracy: 0.9785%\n",
            "1875/1875 - 5s - loss: 0.0158 - accuracy: 0.9950 - 5s/epoch - 3ms/step\n",
            "Epoch [48/50], Train Accuracy: 0.9893%, Val Accuracy: 0.9781%\n",
            "1875/1875 - 5s - loss: 0.0152 - accuracy: 0.9953 - 5s/epoch - 3ms/step\n",
            "Epoch [49/50], Train Accuracy: 0.9908%, Val Accuracy: 0.9790%\n",
            "1875/1875 - 5s - loss: 0.0145 - accuracy: 0.9956 - 5s/epoch - 3ms/step\n",
            "Epoch [50/50], Train Accuracy: 0.9906%, Val Accuracy: 0.9789%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Conv2D(2, kernel_size=3, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Conv2D(4, kernel_size=3, padding='same', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Count the total number of trainable parameters\n",
        "total_params = model.count_params()\n",
        "print(\"Total Trainable Parameters:\", total_params)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train, batch_size=32, epochs=1, verbose=2)\n",
        "\n",
        "    # Evaluate the model\n",
        "    _, train_accuracy = model.evaluate(x_train, y_train, verbose=0)\n",
        "    _, val_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "          f\"Train Accuracy: {train_accuracy:.4f}%, \"\n",
        "          f\"Val Accuracy: {val_accuracy:.4f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0Y4vNbeUUVw",
        "outputId": "c36d860c-7d57-4ec1-8078-a6b2e8fc2d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Trainable Parameters: 2090\n",
            "1875/1875 - 8s - loss: 0.3861 - accuracy: 0.8813 - 8s/epoch - 4ms/step\n",
            "Epoch [1/50], Train Accuracy: 0.9516%, Val Accuracy: 0.9533%\n",
            "1875/1875 - 6s - loss: 0.1345 - accuracy: 0.9591 - 6s/epoch - 3ms/step\n",
            "Epoch [2/50], Train Accuracy: 0.9653%, Val Accuracy: 0.9650%\n",
            "1875/1875 - 6s - loss: 0.1073 - accuracy: 0.9668 - 6s/epoch - 3ms/step\n",
            "Epoch [3/50], Train Accuracy: 0.9693%, Val Accuracy: 0.9682%\n",
            "1875/1875 - 5s - loss: 0.0968 - accuracy: 0.9702 - 5s/epoch - 3ms/step\n",
            "Epoch [4/50], Train Accuracy: 0.9720%, Val Accuracy: 0.9685%\n",
            "1875/1875 - 5s - loss: 0.0909 - accuracy: 0.9722 - 5s/epoch - 3ms/step\n",
            "Epoch [5/50], Train Accuracy: 0.9722%, Val Accuracy: 0.9691%\n",
            "1875/1875 - 5s - loss: 0.0868 - accuracy: 0.9735 - 5s/epoch - 3ms/step\n",
            "Epoch [6/50], Train Accuracy: 0.9728%, Val Accuracy: 0.9699%\n",
            "1875/1875 - 5s - loss: 0.0837 - accuracy: 0.9741 - 5s/epoch - 3ms/step\n",
            "Epoch [7/50], Train Accuracy: 0.9728%, Val Accuracy: 0.9691%\n",
            "1875/1875 - 5s - loss: 0.0813 - accuracy: 0.9747 - 5s/epoch - 3ms/step\n",
            "Epoch [8/50], Train Accuracy: 0.9733%, Val Accuracy: 0.9697%\n",
            "1875/1875 - 5s - loss: 0.0792 - accuracy: 0.9754 - 5s/epoch - 3ms/step\n",
            "Epoch [9/50], Train Accuracy: 0.9753%, Val Accuracy: 0.9703%\n",
            "1875/1875 - 6s - loss: 0.0777 - accuracy: 0.9756 - 6s/epoch - 3ms/step\n",
            "Epoch [10/50], Train Accuracy: 0.9741%, Val Accuracy: 0.9692%\n",
            "1875/1875 - 6s - loss: 0.0761 - accuracy: 0.9763 - 6s/epoch - 3ms/step\n",
            "Epoch [11/50], Train Accuracy: 0.9767%, Val Accuracy: 0.9713%\n",
            "1875/1875 - 6s - loss: 0.0749 - accuracy: 0.9766 - 6s/epoch - 3ms/step\n",
            "Epoch [12/50], Train Accuracy: 0.9781%, Val Accuracy: 0.9734%\n",
            "1875/1875 - 6s - loss: 0.0739 - accuracy: 0.9769 - 6s/epoch - 3ms/step\n",
            "Epoch [13/50], Train Accuracy: 0.9785%, Val Accuracy: 0.9733%\n",
            "1875/1875 - 5s - loss: 0.0730 - accuracy: 0.9774 - 5s/epoch - 3ms/step\n",
            "Epoch [14/50], Train Accuracy: 0.9786%, Val Accuracy: 0.9734%\n",
            "1875/1875 - 6s - loss: 0.0722 - accuracy: 0.9774 - 6s/epoch - 3ms/step\n",
            "Epoch [15/50], Train Accuracy: 0.9791%, Val Accuracy: 0.9741%\n",
            "1875/1875 - 6s - loss: 0.0715 - accuracy: 0.9777 - 6s/epoch - 3ms/step\n",
            "Epoch [16/50], Train Accuracy: 0.9793%, Val Accuracy: 0.9742%\n",
            "1875/1875 - 5s - loss: 0.0709 - accuracy: 0.9779 - 5s/epoch - 3ms/step\n",
            "Epoch [17/50], Train Accuracy: 0.9793%, Val Accuracy: 0.9744%\n",
            "1875/1875 - 5s - loss: 0.0703 - accuracy: 0.9783 - 5s/epoch - 3ms/step\n",
            "Epoch [18/50], Train Accuracy: 0.9797%, Val Accuracy: 0.9747%\n",
            "1875/1875 - 6s - loss: 0.0697 - accuracy: 0.9785 - 6s/epoch - 3ms/step\n",
            "Epoch [19/50], Train Accuracy: 0.9800%, Val Accuracy: 0.9745%\n",
            "1875/1875 - 5s - loss: 0.0692 - accuracy: 0.9785 - 5s/epoch - 3ms/step\n",
            "Epoch [20/50], Train Accuracy: 0.9799%, Val Accuracy: 0.9747%\n",
            "1875/1875 - 5s - loss: 0.0687 - accuracy: 0.9786 - 5s/epoch - 3ms/step\n",
            "Epoch [21/50], Train Accuracy: 0.9800%, Val Accuracy: 0.9747%\n",
            "1875/1875 - 6s - loss: 0.0682 - accuracy: 0.9792 - 6s/epoch - 3ms/step\n",
            "Epoch [22/50], Train Accuracy: 0.9804%, Val Accuracy: 0.9749%\n",
            "1875/1875 - 6s - loss: 0.0676 - accuracy: 0.9793 - 6s/epoch - 3ms/step\n",
            "Epoch [23/50], Train Accuracy: 0.9804%, Val Accuracy: 0.9752%\n",
            "1875/1875 - 5s - loss: 0.0673 - accuracy: 0.9793 - 5s/epoch - 3ms/step\n",
            "Epoch [24/50], Train Accuracy: 0.9807%, Val Accuracy: 0.9749%\n",
            "1875/1875 - 6s - loss: 0.0669 - accuracy: 0.9794 - 6s/epoch - 3ms/step\n",
            "Epoch [25/50], Train Accuracy: 0.9806%, Val Accuracy: 0.9753%\n",
            "1875/1875 - 6s - loss: 0.0664 - accuracy: 0.9795 - 6s/epoch - 3ms/step\n",
            "Epoch [26/50], Train Accuracy: 0.9808%, Val Accuracy: 0.9750%\n",
            "1875/1875 - 6s - loss: 0.0660 - accuracy: 0.9797 - 6s/epoch - 3ms/step\n",
            "Epoch [27/50], Train Accuracy: 0.9806%, Val Accuracy: 0.9744%\n",
            "1875/1875 - 5s - loss: 0.0657 - accuracy: 0.9800 - 5s/epoch - 3ms/step\n",
            "Epoch [28/50], Train Accuracy: 0.9809%, Val Accuracy: 0.9744%\n",
            "1875/1875 - 6s - loss: 0.0654 - accuracy: 0.9800 - 6s/epoch - 3ms/step\n",
            "Epoch [29/50], Train Accuracy: 0.9808%, Val Accuracy: 0.9746%\n",
            "1875/1875 - 5s - loss: 0.0651 - accuracy: 0.9799 - 5s/epoch - 3ms/step\n",
            "Epoch [30/50], Train Accuracy: 0.9810%, Val Accuracy: 0.9745%\n",
            "1875/1875 - 5s - loss: 0.0648 - accuracy: 0.9800 - 5s/epoch - 3ms/step\n",
            "Epoch [31/50], Train Accuracy: 0.9809%, Val Accuracy: 0.9740%\n",
            "1875/1875 - 6s - loss: 0.0645 - accuracy: 0.9801 - 6s/epoch - 3ms/step\n",
            "Epoch [32/50], Train Accuracy: 0.9809%, Val Accuracy: 0.9747%\n",
            "1875/1875 - 5s - loss: 0.0642 - accuracy: 0.9803 - 5s/epoch - 3ms/step\n",
            "Epoch [33/50], Train Accuracy: 0.9808%, Val Accuracy: 0.9741%\n",
            "1875/1875 - 5s - loss: 0.0640 - accuracy: 0.9802 - 5s/epoch - 3ms/step\n",
            "Epoch [34/50], Train Accuracy: 0.9809%, Val Accuracy: 0.9744%\n",
            "1875/1875 - 6s - loss: 0.0638 - accuracy: 0.9803 - 6s/epoch - 3ms/step\n",
            "Epoch [35/50], Train Accuracy: 0.9807%, Val Accuracy: 0.9745%\n",
            "1875/1875 - 6s - loss: 0.0635 - accuracy: 0.9803 - 6s/epoch - 3ms/step\n",
            "Epoch [36/50], Train Accuracy: 0.9810%, Val Accuracy: 0.9746%\n",
            "1875/1875 - 6s - loss: 0.0633 - accuracy: 0.9805 - 6s/epoch - 3ms/step\n",
            "Epoch [37/50], Train Accuracy: 0.9812%, Val Accuracy: 0.9754%\n",
            "1875/1875 - 6s - loss: 0.0630 - accuracy: 0.9804 - 6s/epoch - 3ms/step\n",
            "Epoch [38/50], Train Accuracy: 0.9814%, Val Accuracy: 0.9754%\n",
            "1875/1875 - 5s - loss: 0.0629 - accuracy: 0.9804 - 5s/epoch - 3ms/step\n",
            "Epoch [39/50], Train Accuracy: 0.9814%, Val Accuracy: 0.9752%\n",
            "1875/1875 - 5s - loss: 0.0627 - accuracy: 0.9806 - 5s/epoch - 3ms/step\n",
            "Epoch [40/50], Train Accuracy: 0.9816%, Val Accuracy: 0.9752%\n",
            "1875/1875 - 5s - loss: 0.0625 - accuracy: 0.9806 - 5s/epoch - 3ms/step\n",
            "Epoch [41/50], Train Accuracy: 0.9815%, Val Accuracy: 0.9756%\n",
            "1875/1875 - 6s - loss: 0.0623 - accuracy: 0.9806 - 6s/epoch - 3ms/step\n",
            "Epoch [42/50], Train Accuracy: 0.9813%, Val Accuracy: 0.9755%\n",
            "1875/1875 - 6s - loss: 0.0622 - accuracy: 0.9807 - 6s/epoch - 3ms/step\n",
            "Epoch [43/50], Train Accuracy: 0.9813%, Val Accuracy: 0.9755%\n",
            "1875/1875 - 5s - loss: 0.0620 - accuracy: 0.9806 - 5s/epoch - 3ms/step\n",
            "Epoch [44/50], Train Accuracy: 0.9815%, Val Accuracy: 0.9754%\n",
            "1875/1875 - 5s - loss: 0.0618 - accuracy: 0.9808 - 5s/epoch - 3ms/step\n",
            "Epoch [45/50], Train Accuracy: 0.9813%, Val Accuracy: 0.9752%\n",
            "1875/1875 - 5s - loss: 0.0617 - accuracy: 0.9809 - 5s/epoch - 3ms/step\n",
            "Epoch [46/50], Train Accuracy: 0.9816%, Val Accuracy: 0.9753%\n",
            "1875/1875 - 6s - loss: 0.0615 - accuracy: 0.9808 - 6s/epoch - 3ms/step\n",
            "Epoch [47/50], Train Accuracy: 0.9817%, Val Accuracy: 0.9754%\n",
            "1875/1875 - 6s - loss: 0.0614 - accuracy: 0.9808 - 6s/epoch - 3ms/step\n",
            "Epoch [48/50], Train Accuracy: 0.9816%, Val Accuracy: 0.9754%\n",
            "1875/1875 - 6s - loss: 0.0612 - accuracy: 0.9809 - 6s/epoch - 3ms/step\n",
            "Epoch [49/50], Train Accuracy: 0.9816%, Val Accuracy: 0.9754%\n",
            "1875/1875 - 5s - loss: 0.0610 - accuracy: 0.9809 - 5s/epoch - 3ms/step\n",
            "Epoch [50/50], Train Accuracy: 0.9818%, Val Accuracy: 0.9759%\n"
          ]
        }
      ]
    }
  ]
}